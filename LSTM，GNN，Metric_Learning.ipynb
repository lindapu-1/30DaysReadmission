{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "l0nonu-bgvqs"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lindapu-1/30DaysReadmission/blob/main/LSTM%EF%BC%8CGNN%EF%BC%8CMetric_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFN8fPQ4UfHT"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "zip_data_path = \"/gdrive/MyDrive/all_data_3612.zip\"\n",
        "\n",
        "!mkdir all_data_3612\n",
        "extract_path = '/content/all_data_3612'\n",
        "\n",
        "with zipfile.ZipFile(zip_data_path, 'r') as zip_ref:\n",
        "   zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "Yo8DNJzsXCYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b06ce2c0-85df-4192-804d-7463c13fd092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QDS9jfnWV0O",
        "outputId": "512d3256-dfce-4545-a125-3ff1d4d96af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/all_data_3612/ehr_preprocessed_seq_by_day_cat_embedding.pkl', 'rb') as f:\n",
        "  data = pickle.load(f)\n",
        "\n",
        "data.keys()"
      ],
      "metadata": {
        "id": "AfY_eNgWYrx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e63032be-931d-49c0-b745-b76625f2f671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['feat_dict', 'feature_cols', 'cat_idxs', 'cat_dims', 'demo_cols', 'icd_cols', 'lab_cols', 'med_cols'])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['feat_dict']['12703486_29751691']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aanhqPyDSdQw",
        "outputId": "a5f5e418-4602-4540-eff5-d12f2cf0e706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[42,  1,  4, ...,  0,  0,  0],\n",
              "       [42,  1,  4, ...,  0,  0,  0],\n",
              "       [42,  1,  4, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [42,  1,  4, ...,  0,  0,  0],\n",
              "       [42,  1,  4, ...,  0,  0,  0],\n",
              "       [42,  1,  4, ...,  0,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['feat_dict']['14329220_29149180']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haqPW79ERi5u",
        "outputId": "333f21a6-ee05-4ac0-a61c-a62e676fd044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[72,  1,  6, ...,  0,  0,  1],\n",
              "       [72,  1,  6, ...,  0,  0,  1],\n",
              "       [72,  1,  6, ...,  0,  0,  1],\n",
              "       ...,\n",
              "       [72,  1,  6, ...,  0,  0,  1],\n",
              "       [72,  1,  6, ...,  0,  0,  1],\n",
              "       [72,  1,  6, ...,  0,  0,  1]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_csv(\"/content/all_data_3612/train.csv\")\n",
        "df_valid = pd.read_csv(\"/content/all_data_3612/valid.csv\")\n",
        "df_test = pd.read_csv(\"/content/all_data_3612/test.csv\")"
      ],
      "metadata": {
        "id": "ftr1M-z0joNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, feat_dict):\n",
        "        self.df = dataframe.drop_duplicates(subset=['id'], keep='first')\n",
        "        self.feat_dict = feat_dict\n",
        "        self.mean, self.std = self.compute_stats()\n",
        "\n",
        "    def compute_stats(self):\n",
        "        # Combine only the selected features into a large array\n",
        "        selected_features = torch.cat([torch.tensor(self.feat_dict[id][:, :], dtype=torch.float32) for id in self.df['id']])\n",
        "        # Calculate mean and standard deviation for these features\n",
        "        mean = selected_features.mean(dim=0)\n",
        "        std = selected_features.std(dim=0)\n",
        "        return mean, std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        # Select only the relevant features\n",
        "        features = torch.tensor(self.feat_dict[row['id']][:, ], dtype=torch.float32)\n",
        "        # Check if the column exists, otherwise assign -1\n",
        "        label = row['readmitted_within_30days'] if 'readmitted_within_30days' in self.df.columns else -1\n",
        "        # Apply normalization to the selected features\n",
        "        features = (features - self.mean) / (self.std + 1e-6)  # To avoid division by zero\n",
        "        return features, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# Example usage\n",
        "train_dataset = CustomDataset(df_train, data['feat_dict'])\n",
        "valid_dataset = CustomDataset(df_valid, data['feat_dict'])\n",
        "test_dataset = CustomDataset(df_test, data['feat_dict'])"
      ],
      "metadata": {
        "id": "Q-pighWnT9h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4xxDaYMViyQ",
        "outputId": "cb25c404-e59f-4bed-df30-247c5e4f414e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 171])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 假设 train_dataset 和 valid_dataset 是您的PyTorch Dataset对象\n",
        "\n",
        "def extract_features_and_labels(dataset):\n",
        "    features_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    for features, label in dataset:\n",
        "        # 假设 features 是一个 (time_steps, num_features) 形状的张量\n",
        "        # 对时间维度进行平均\n",
        "        # features_mean = features.mean(dim=0)  # 对时间维度取平均值\n",
        "        features_mean = features.mean(dim=0)  # 对时间维度取平均值\n",
        "        features_list.append(features_mean.numpy())  # 转换为NumPy数组并存储\n",
        "        labels_list.append(label.item())  # 存储标签\n",
        "\n",
        "    # 将列表转换为NumPy数组\n",
        "    features_array = np.array(features_list)\n",
        "    labels_array = np.array(labels_list)\n",
        "\n",
        "    return features_array, labels_array\n",
        "\n",
        "# 提取训练和测试特征\n",
        "train_features, train_labels = extract_features_and_labels(train_dataset)\n",
        "valid_features, valid_labels = extract_features_and_labels(valid_dataset)\n",
        "test_features, test_labels = extract_features_and_labels(test_dataset)"
      ],
      "metadata": {
        "id": "P9fmZxQUZmVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# 假设 train_features, test_features 是训练和测试特征数据\n",
        "# train_labels 是训练数据的标签\n",
        "\n",
        "# 用于存储所有测试点的预测概率\n",
        "predicted_probabilities_list = []\n",
        "\n",
        "# 对于测试数据中的每个点\n",
        "from tqdm import tqdm\n",
        "for test_point in tqdm(valid_features):\n",
        "    # 计算与训练集中每个点的距离\n",
        "    distances = np.linalg.norm(train_features - test_point, axis=1)\n",
        "    nearest_indices = np.argsort(distances)[:20]\n",
        "    nearest_features = train_features[nearest_indices]\n",
        "    nearest_labels = train_labels[nearest_indices]\n",
        "\n",
        "    # 检查是否只有一个类别\n",
        "    unique_labels = np.unique(nearest_labels)\n",
        "    if len(unique_labels) == 1:\n",
        "        # 如果只有一个类别，预测概率为1.0或0.0，取决于该类别\n",
        "        predicted_probability = 1.0 if unique_labels[0] == 1 else 0.0\n",
        "    else:\n",
        "        # 如果有多个类别，正常训练和预测\n",
        "        svm_model = SVC(kernel='rbf', probability=True)\n",
        "        svm_model.fit(nearest_features, nearest_labels)\n",
        "        predicted_probability = svm_model.predict_proba(test_point.reshape(1, -1))[0, 1]\n",
        "\n",
        "    predicted_probabilities_list.append(predicted_probability)\n",
        "\n",
        "# 计算整个测试集的ROC-AUC\n",
        "roc_auc = roc_auc_score(valid_labels, predicted_probabilities_list)\n",
        "print(\"ROC-AUC for the entire test set:\", roc_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "768wt2QKX93B",
        "outputId": "97baf3b8-a5f2-4cf0-d46e-0cd76f7e4598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2325/2325 [00:12<00:00, 189.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC for the entire test set: 0.6504714802653283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# 初始化KNN模型\n",
        "knn = KNeighborsClassifier(n_neighbors=300, weights = \"distance\")\n",
        "\n",
        "# 训练模型\n",
        "knn.fit(train_features, train_labels)\n",
        "\n",
        "# 预测测试集的概率\n",
        "predicted_probabilities = knn.predict_proba(valid_features)[:, 1]  # 获取正类的概率\n",
        "\n",
        "# 计算整个测试集的ROC-AUC\n",
        "roc_auc = roc_auc_score(valid_labels, predicted_probabilities)\n",
        "print(\"ROC-AUC for the entire test set:\", roc_auc)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fzntOIZd57b",
        "outputId": "78df8ef5-66a6-45c9-d7ee-45c59c18a628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC for the entire test set: 0.7494322190023295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_KNN(n = 1000):\n",
        "    # 初始化KNN模型\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=n, weights = \"distance\")\n",
        "\n",
        "    # 训练模型\n",
        "    knn.fit(train_features, train_labels)\n",
        "\n",
        "    # 预测测试集的概率\n",
        "    predicted_probabilities = knn.predict_proba(valid_features)[:, 1]  # 获取正类的概率\n",
        "    # 计算整个测试集的ROC-AUC\n",
        "    roc_auc = roc_auc_score(valid_labels, predicted_probabilities)\n",
        "    print(\"ROC-AUC for the entire test set:\", roc_auc)\n",
        "\n",
        "    predicted_probabilities_test = knn.predict_proba(test_features)[:, 1]  # 获取正类的概率\n",
        "\n",
        "    return predicted_probabilities.tolist() + predicted_probabilities_test.tolist()\n"
      ],
      "metadata": {
        "id": "NqUGwQMUPRDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_ids = df_valid['id'].tolist()\n",
        "test_ids = df_test['id'].tolist()\n",
        "combined_ids = valid_ids + test_ids\n",
        "# Removing adjacent duplicates\n",
        "unique_ids = [combined_ids[i] for i in range(len(combined_ids)) if i == 0 or combined_ids[i] != combined_ids[i-1]]\n",
        "dict_outputDF = {\n",
        "    \"id\": unique_ids,\n",
        "    \"subset\": [\"valid\"] * len(valid_labels)+[\"test\"]*len(test_labels),\n",
        "    \"label\": valid_labels.tolist()+test_labels.tolist(),\n",
        "    \"knn_n=100\": compute_KNN(n=100),\n",
        "    \"knn_n=500\": compute_KNN(n=500),\n",
        "    \"knn_n=1000\": compute_KNN(n=1000),\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QyWyrOYPPt8",
        "outputId": "a7917cfb-d23e-4047-bc9c-dcf0bf991d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC for the entire test set: 0.7308248620831408\n",
            "ROC-AUC for the entire test set: 0.742557310989195\n",
            "ROC-AUC for the entire test set: 0.7464486725978106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = compute_KNN(n=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-JHdXV7VUUB",
        "outputId": "580601c7-27e9-4839-9390-97d377cf328d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC for the entire test set: 0.7096317226538909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(dict_outputDF)\n",
        "df.to_csv('/content/gdrive/MyDrive/KNN.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "eqGEe_kbRRq0",
        "outputId": "19a5418f-a311-4da5-f767-cc352ddaf1de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-157-f406c7d7654d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_outputDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/KNN.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3718\u001b[0m         )\n\u001b[1;32m   3719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3720\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3721\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3722\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         )\n\u001b[0;32m-> 1189\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \"\"\"\n\u001b[1;32m    240\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/content/gdrive/MyDrive'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metric Learning"
      ],
      "metadata": {
        "id": "26RrZP2V5U8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ResidualEmbeddingNet(nn.Module):\n",
        "    def __init__(self, num_features, embedding_dim=64):\n",
        "        super(ResidualEmbeddingNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_features, 32)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc2 = nn.Linear(32, embedding_dim)\n",
        "        # 如果输入特征维度与输出嵌入维度不同，需要一个额外的转换层\n",
        "        if num_features != embedding_dim:\n",
        "            self.shortcut = nn.Linear(num_features, embedding_dim)\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.shortcut(x)\n",
        "        out = self.relu(self.fc1(x))\n",
        "        out = self.fc2(out)\n",
        "        out += identity  # 添加残差连接\n",
        "        return out"
      ],
      "metadata": {
        "id": "t1h8Kl3W5Wxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TripletLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, anchor, positives=None, negatives=None):\n",
        "        # 初始化损失为0\n",
        "        loss = torch.tensor(0.0, device=anchor.device)\n",
        "\n",
        "        # 计算正样本的平均距离\n",
        "        if positives is not None and len(positives) > 0:\n",
        "            distance_positives = [(anchor - p).pow(2).sum(1) for p in positives]\n",
        "            average_distance_positive = torch.stack(distance_positives).mean(0)\n",
        "\n",
        "        # 计算负样本的平均距离\n",
        "        if negatives is not None and len(negatives) > 0:\n",
        "            distance_negatives = [(anchor - n).pow(2).sum(1) for n in negatives]\n",
        "            average_distance_negative = torch.stack(distance_negatives).mean(0)\n",
        "\n",
        "        # 根据正负样本的存在情况计算损失\n",
        "        if positives is not None and negatives is not None and len(positives) > 0 and len(negatives) > 0:\n",
        "            loss = F.relu(average_distance_positive + self.margin)\n",
        "        elif positives is not None and len(positives) > 0:\n",
        "            loss = average_distance_positive\n",
        "        elif negatives is not None and len(negatives) > 0:\n",
        "            # loss = -average_distance_negative + self.margin\n",
        "            loss = 0\n",
        "\n",
        "        return loss.mean()\n"
      ],
      "metadata": {
        "id": "GfDrK5qQ5XlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResidualEmbeddingNet(num_features=171)\n",
        "loss_fn = TripletLoss(margin=1.0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Including L1 penalty\n",
        "l1_lambda = 0.001  # Adjust this value for the strength of the L1 penalty\n",
        "\n",
        "\n",
        "# Check for CUDA\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Prepare data for Nearest Neighbors and move to device\n",
        "train_features = torch.tensor(train_features).to(device)\n",
        "train_labels = torch.tensor(train_labels).to(device)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 1\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # Compute nearest neighbors\n",
        "    from sklearn.neighbors import NearestNeighbors\n",
        "    nbrs = NearestNeighbors(n_neighbors=200, algorithm='auto').fit(train_features.cpu().numpy())\n",
        "    distances, indices = nbrs.kneighbors(train_features.cpu().numpy())\n",
        "    from tqdm import trange\n",
        "    for i in trange(train_features.size(0)):\n",
        "        anchor = train_features[i].unsqueeze(0)\n",
        "        neighbors = train_features[indices[i]]\n",
        "\n",
        "        # Create positive and negative masks based on labels\n",
        "        positive_mask = train_labels[indices[i]] == train_labels[i]\n",
        "        negative_mask = ~positive_mask\n",
        "\n",
        "        # Extract positives and negatives\n",
        "        positives = neighbors[positive_mask]\n",
        "        negatives = neighbors[negative_mask]\n",
        "\n",
        "        # Get embeddings from the model\n",
        "        anchor_embedding = model(anchor)\n",
        "        positive_embeddings = model(positives) if positives.size(0) > 0 else None\n",
        "        negative_embeddings = model(negatives) if negatives.size(0) > 0 else None\n",
        "\n",
        "        # Compute triplet loss\n",
        "        triplet_loss = loss_fn(anchor_embedding, positive_embeddings, negative_embeddings)\n",
        "\n",
        "        # Calculate L1 penalty (sum of absolute values of all parameters)\n",
        "        l1_penalty = sum(p.abs().sum() for p in model.parameters())\n",
        "\n",
        "        # Total loss = Triplet loss + L1 penalty\n",
        "        total_loss = triplet_loss + l1_lambda * l1_penalty\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += total_loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss / train_features.size(0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO-CEPaeP8o4",
        "outputId": "70cd7544-eb9b-4185-c008-3960e690a1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9271/9271 [04:42<00:00, 32.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.8745197181163669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def evaluate_with_knn(model, n_neighbors=100):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # Move model to the same device as the data\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Extract embeddings from the model\n",
        "    with torch.no_grad():\n",
        "        train_embeddings = model(torch.tensor(train_features).to(device)).cpu().numpy()\n",
        "        valid_embeddings = model(torch.tensor(valid_features).to(device)).cpu().numpy()\n",
        "\n",
        "    # Initialize and train KNN classifier\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, weights=\"distance\")\n",
        "    knn.fit(train_embeddings, train_labels.cpu().numpy())\n",
        "\n",
        "    # Predict probabilities on the validation set\n",
        "    predicted_probabilities = knn.predict_proba(valid_embeddings)[:, 1]\n",
        "\n",
        "    # Compute ROC-AUC\n",
        "    roc_auc = roc_auc_score(valid_labels, predicted_probabilities)\n",
        "    print(\"ROC-AUC for the validation set:\", roc_auc)\n",
        "\n",
        "# Example of using the function\n",
        "evaluate_with_knn(model, n_neighbors=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hFqVwnvTb5J",
        "outputId": "e83b51c6-3f34-4bc9-a55f-25c3e41ec973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-151-948e6d6e1756>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_embeddings = model(torch.tensor(train_features).to(device)).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC for the validation set: 0.6554260831612017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GNN"
      ],
      "metadata": {
        "id": "l0nonu-bgvqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CffXS2RgzWV",
        "outputId": "29af8590-188d-4d17-a755-e2feff822dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rest of your code with some modifications\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "import numpy as np\n",
        "\n",
        "# Combine features and labels from all sets\n",
        "all_features = torch.cat((torch.tensor(train_features), torch.tensor(valid_features), torch.tensor(test_features)), 0)\n",
        "all_labels = torch.cat((torch.tensor(train_labels), torch.tensor(valid_labels), torch.tensor(test_labels)), 0)\n",
        "\n",
        "# Create a graph\n",
        "A = kneighbors_graph(all_features.numpy(), n_neighbors=20, mode='distance', include_self=True)\n",
        "edges = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "data = Data(x=all_features, edge_index=edges, y=all_labels)\n",
        "num_train = len(train_labels)\n",
        "num_valid = len(valid_labels)\n",
        "num_test = len(test_labels)\n",
        "num_nodes = all_features.shape[0]\n",
        "\n",
        "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "valid_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "train_mask[:num_train] = True\n",
        "valid_mask[num_train:num_train + num_valid] = True\n",
        "test_mask[num_train + num_valid:num_train + num_valid + num_test] = True\n",
        "\n",
        "data.train_mask = train_mask\n",
        "data.valid_mask = valid_mask\n",
        "data.test_mask = test_mask"
      ],
      "metadata": {
        "id": "oTdaAVqggwwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdc1vuLljL1Q",
        "outputId": "fb4bde6a-f828-41e1-e914-b2c9edd46a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[11596, 171], edge_index=[2, 1159600], y=[11596], train_mask=[11596], test_mask=[11596])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class DeepGCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes, dropout_rate=0.5):\n",
        "        super(DeepGCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, 32)\n",
        "        self.conv2 = GCNConv(32, 32)\n",
        "        self.conv3 = GCNConv(32, 32)  # Added missing conv3 layer\n",
        "        self.conv4 = GCNConv(32, 32)\n",
        "        self.conv5 = GCNConv(32, num_classes)\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x1 = F.relu(self.conv1(x, edge_index))  # First layer\n",
        "        x = F.dropout(x1, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        x2 = F.relu(self.conv2(x, edge_index)) + x  # Second layer\n",
        "        x = F.dropout(x2, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        x3 = F.relu(self.conv3(x, edge_index)) + x  # Third layer with residual connection from first layer\n",
        "        x = F.dropout(x3, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        x4 = F.relu(self.conv4(x, edge_index)) + x  # Fourth layer with residual connection from second layer\n",
        "        x = F.dropout(x4, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        x = self.conv5(x, edge_index)  # Output layer\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "8-enLYAugxcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KamsbxmfqDoT",
        "outputId": "c4d4ad89-8096-4359-af39-7bd21a2ff7c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_FEATURES = 171\n",
        "NUM_CLASSES = 2\n",
        "NUM_EPOCHS = 500\n",
        "\n",
        "# 将模型移动到指定的设备（GPU或CPU）\n",
        "model = DeepGCN(num_features=NUM_FEATURES, num_classes=NUM_CLASSES).to(device)\n",
        "\n",
        "# 确保数据也在同一设备上\n",
        "data = data.to(device)\n",
        "\n",
        "# 修改优化器设置\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# 存储性能指标\n",
        "accuracies = []\n",
        "roc_aucs = []\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tqdm import trange\n",
        "for epoch in trange(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # 测试模型\n",
        "    model.eval()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        with torch.no_grad():\n",
        "            logits = model(data)\n",
        "            probabilities = F.softmax(logits, dim=1)\n",
        "            preds = probabilities.argmax(dim=1)\n",
        "            correct = preds[data.valid_mask].eq(data.y[data.valid_mask]).sum().item()\n",
        "            accuracy = correct / data.valid_mask.sum().item()\n",
        "\n",
        "            accuracies.append(accuracy)\n",
        "        # 计算ROC-AUC\n",
        "        y_true = data.y[data.valid_mask].cpu().numpy()  # 将数据移回CPU来计算ROC-AUC\n",
        "        y_score = probabilities[data.valid_mask, 1].cpu().numpy()\n",
        "        roc_auc = roc_auc_score(y_true, y_score)\n",
        "        roc_aucs.append(roc_auc)\n",
        "        print(f'Epoch {epoch+1}, Loss: {loss.item()}, Accuracy: {accuracy}, ROC-AUC: {roc_auc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzvpEIBFs2tj",
        "outputId": "28e37ef3-0599-4103-a892-f3d8d0ef876e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 11/500 [00:00<00:09, 50.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 4.100464820861816, Accuracy: 0.8227956989247311, ROC-AUC: 0.5126491456006171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 110/500 [00:02<00:08, 44.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 101, Loss: 0.4316958785057068, Accuracy: 0.8210752688172043, ROC-AUC: 0.6946727551398455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 210/500 [00:03<00:03, 77.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 201, Loss: 0.41761478781700134, Accuracy: 0.821505376344086, ROC-AUC: 0.7027644273468704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 317/500 [00:04<00:02, 81.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 301, Loss: 0.40675121545791626, Accuracy: 0.8356989247311828, ROC-AUC: 0.7039037956952685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 416/500 [00:06<00:01, 80.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 401, Loss: 0.4013436436653137, Accuracy: 0.8365591397849462, ROC-AUC: 0.7117810433467486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:07<00:00, 69.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Epoch {epoch+1}, Loss: {loss.item()}, Accuracy: {accuracy}, ROC-AUC: {roc_auc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irTt_IYbvr7Y",
        "outputId": "a59f1a6a-28d7-4370-ac15-9489ba9c8fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss: 0.3915436863899231, Accuracy: 0.8365591397849462, ROC-AUC: 0.7117810433467486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_valid_gnn = probabilities[data.valid_mask, 1].cpu().numpy()\n",
        "score_test_gnn = probabilities[data.test_mask, 1].cpu().numpy()"
      ],
      "metadata": {
        "id": "FH301aKrFtWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gnn, y_score_gnn = model, y_score"
      ],
      "metadata": {
        "id": "uiXjEEAKvxbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CKqV7eSGGptv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "86huX2kFX-Js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=3, dropout_rate=0.8):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        # 定义三层LSTM，每层之间添加dropout\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers,\n",
        "                            batch_first=True, dropout=dropout_rate)\n",
        "        # Dropout层\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        # 定义线性层\n",
        "        self.fc_token = nn.Linear(hidden_size, output_size)  # 用于 token 改变量的预测\n",
        "        self.fc_label = nn.Linear(hidden_size, 1)  # 用于每个时间步的标签预测\n",
        "\n",
        "    def forward(self, x):\n",
        "        # LSTM 层\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        # 应用dropout\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        # 在每个时间步预测 token 的改变量\n",
        "        token_change = self.fc_token(lstm_out)\n",
        "        # 在每个时间步预测标签\n",
        "        labels = self.fc_label(lstm_out)\n",
        "        return token_change, labels"
      ],
      "metadata": {
        "id": "kdGvyz3-U78_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(model, eval_dataset):\n",
        "    model.eval()  # 设置模型为评估模式\n",
        "\n",
        "    # 确保模型在 GPU 上\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():  # 在评估过程中不计算梯度\n",
        "        for features, label in eval_dataset:\n",
        "            # 将数据移至 GPU\n",
        "            features = features.cuda() if torch.cuda.is_available() else features\n",
        "            label = label.cuda() if torch.cuda.is_available() else label\n",
        "\n",
        "            # 前向传播\n",
        "            _, label_pred = model(features.unsqueeze(0))\n",
        "\n",
        "            # 将预测转换为二元概率（sigmoid 函数）\n",
        "            label_prob = torch.sigmoid(label_pred).squeeze().cpu().numpy()[-1]\n",
        "            predictions.append(label_prob)\n",
        "\n",
        "            # 保存真实标签\n",
        "            true_labels.append(label.cpu().numpy())\n",
        "\n",
        "    # 计算 ROC-AUC 分数\n",
        "    roc_auc = roc_auc_score(true_labels, predictions)\n",
        "    return roc_auc, predictions"
      ],
      "metadata": {
        "id": "OcVnxJGmHDd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def train_model(train_dataset, valid_dataset, num_epochs):\n",
        "    # 创建模型实例\n",
        "    model = LSTMModel(input_size=171, hidden_size=64, output_size=171)\n",
        "\n",
        "    # 检查 CUDA 是否可用，并将模型移至 GPU\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "\n",
        "    # 定义优化器和损失函数\n",
        "    criterion_token = nn.MSELoss()\n",
        "    criterion_label = nn.BCEWithLogitsLoss(reduction='none')\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
        "\n",
        "    best_roc_auc = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # 设置模型为训练模式\n",
        "        total_loss = 0\n",
        "        from tqdm import tqdm\n",
        "        for features, label in tqdm(train_dataset):\n",
        "            features = features.cuda() if torch.cuda.is_available() else features\n",
        "            label = label.cuda() if torch.cuda.is_available() else label\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            token_change_pred, label_pred = model(features.unsqueeze(0))\n",
        "            label_pred = label_pred[-1]\n",
        "\n",
        "            actual_token_change = features[1:, :] - features[:-1, :]\n",
        "            loss_token = criterion_token(token_change_pred[:, :-1], actual_token_change.unsqueeze(0))\n",
        "            label = label.float().unsqueeze(0).unsqueeze(-1).expand_as(label_pred)\n",
        "            loss_label = criterion_label(label_pred, label).mean()\n",
        "            loss = loss_label * 10\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_dataset)}\")\n",
        "\n",
        "        # 验证步骤\n",
        "        current_roc_auc, _ = evaluate_model(model, valid_dataset)\n",
        "        print(f\"Validation ROC-AUC for Epoch {epoch+1}: {current_roc_auc}\")\n",
        "\n",
        "        # 检查是否需要更新最佳模型\n",
        "        if current_roc_auc > best_roc_auc:\n",
        "            best_roc_auc = current_roc_auc\n",
        "            best_model = model.state_dict()\n",
        "\n",
        "    # 保存最佳模型\n",
        "    if best_model is not None:\n",
        "        torch.save(best_model, 'best_model.pth')\n",
        "        print(\"Best model saved.\")\n",
        "\n",
        "    return best_model, best_roc_auc, model\n",
        "\n",
        "# 使用\n",
        "num_epochs = 10\n",
        "best_model, best_roc_auc, model = train_model(train_dataset, valid_dataset, num_epochs)\n",
        "best_roc_auc"
      ],
      "metadata": {
        "id": "-zSyg7pBXwEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d48ffc-4a42-49e4-8afd-e22352f1b4c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9271/9271 [00:32<00:00, 285.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 4.488138884931189\n",
            "Validation ROC-AUC for Epoch 1: 0.7376877166449283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9271/9271 [00:30<00:00, 307.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Loss: 4.278274439033368\n",
            "Validation ROC-AUC for Epoch 2: 0.7469568207309213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9271/9271 [00:30<00:00, 306.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Loss: 4.190014379346734\n",
            "Validation ROC-AUC for Epoch 3: 0.7397977050228635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9271/9271 [00:30<00:00, 305.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Loss: 4.122295925332021\n",
            "Validation ROC-AUC for Epoch 4: 0.7383290871350341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9271/9271 [00:30<00:00, 305.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Loss: 4.074232265025316\n",
            "Validation ROC-AUC for Epoch 5: 0.739044681509752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9271/9271 [00:30<00:00, 301.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Loss: 4.026083982350204\n",
            "Validation ROC-AUC for Epoch 6: 0.7266733996822964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9271/9271 [00:30<00:00, 304.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Loss: 3.96664671183899\n",
            "Validation ROC-AUC for Epoch 7: 0.7239937271301621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9271/9271 [00:30<00:00, 302.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Loss: 3.90329700438365\n",
            "Validation ROC-AUC for Epoch 8: 0.7154294327518917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9271/9271 [00:30<00:00, 304.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Loss: 3.8483108185828794\n",
            "Validation ROC-AUC for Epoch 9: 0.7182994229568767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9271/9271 [00:30<00:00, 303.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Loss: 3.7867991128598275\n",
            "Validation ROC-AUC for Epoch 10: 0.704698054699831\n",
            "Best model saved.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7469568207309213"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def inference_model(model, eval_dataset):\n",
        "    model.eval()  # 设置模型为评估模式\n",
        "\n",
        "    # 确保模型在 GPU 上\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():  # 在评估过程中不计算梯度\n",
        "        for features, label in eval_dataset:\n",
        "            # 将数据移至 GPU\n",
        "            features = features.cuda() if torch.cuda.is_available() else features\n",
        "            label = label.cuda() if torch.cuda.is_available() else label\n",
        "\n",
        "            # 前向传播\n",
        "            _, label_pred = model(features.unsqueeze(0))\n",
        "\n",
        "            # 将预测转换为二元概率（sigmoid 函数）\n",
        "            label_prob = torch.sigmoid(label_pred).squeeze().cpu().numpy()[-1]\n",
        "            predictions.append(label_prob)\n",
        "\n",
        "            # 保存真实标签\n",
        "            true_labels.append(label.cpu().numpy())\n",
        "\n",
        "    # 计算 ROC-AUC 分数\n",
        "    # roc_auc = roc_auc_score(true_labels, predictions)\n",
        "    return predictions\n",
        "\n",
        "# 使用\n",
        "# valid_dataset 应该是一个适当的 DataLoader\n",
        "valid_output_lstm_last = inference_model(model, valid_dataset)\n",
        "test_output_lstm_last = inference_model(model, test_dataset)\n",
        "roc_auc_score(valid_labels, valid_output_lstm_last)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRXRbgLmbj2T",
        "outputId": "18aaa627-b45c-477b-98ac-2ea06e50bd6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7865460644846959"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(best_model)\n",
        "valid_output_lstm_best = inference_model(model, valid_dataset)\n",
        "test_output_lstm_best = inference_model(model, test_dataset)\n",
        "roc_auc_score(valid_labels, valid_output_lstm_best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zx0oSq8HdQ6",
        "outputId": "02637b90-8af5-4b2c-c8a5-580b50972e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7865460644846959"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_full = valid_output_lstm_last+test_output_lstm_last"
      ],
      "metadata": {
        "id": "5AWKSVncK_91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_sub = valid_output_lstm_last+test_output_lstm_last"
      ],
      "metadata": {
        "id": "KDrry23lMbxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_ids = df_valid['id'].tolist()\n",
        "test_ids = df_test['id'].tolist()\n",
        "combined_ids = valid_ids + test_ids\n",
        "# Removing adjacent duplicates\n",
        "unique_ids = [combined_ids[i] for i in range(len(combined_ids)) if i == 0 or combined_ids[i] != combined_ids[i-1]]\n",
        "dict_outputDF = {\n",
        "    \"id\": unique_ids,\n",
        "    \"subset\": [\"valid\"] * len(valid_labels)+[\"test\"]*len(test_labels),\n",
        "    \"label\": valid_labels.tolist()+test_labels.tolist(),\n",
        "    \"lstm_full\": lstm_full,\n",
        "    \"lstm_sub\": lstm_sub,\n",
        "}\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(dict_outputDF)\n",
        "df.to_csv('/content/drive/MyDrive/lstm_qwq.csv', index=False)"
      ],
      "metadata": {
        "id": "6EbZWPHxKy9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_ids = df_valid['id'].tolist()\n",
        "test_ids = df_test['id'].tolist()\n",
        "combined_ids = valid_ids + test_ids\n",
        "# Removing adjacent duplicates\n",
        "unique_ids = [combined_ids[i] for i in range(len(combined_ids)) if i == 0 or combined_ids[i] != combined_ids[i-1]]\n",
        "dict_outputDF = {\n",
        "    \"id\": unique_ids,\n",
        "    \"subset\": [\"valid\"] * len(valid_labels)+[\"test\"]*len(test_labels),\n",
        "    \"label\": valid_labels.tolist()+test_labels.tolist(),\n",
        "    # \"lstm_pred_1\": valid_output_lstm_last+test_output_lstm_last,\n",
        "    # \"lstm_pred_2\": valid_output_lstm_best+test_output_lstm_best,\n",
        "}\n",
        "valid_sum = np.array(valid_output_lstm_last)-valid_output_lstm_last\n",
        "for i in range(5):\n",
        "    best_model, best_roc_auc, model = train_model(train_dataset, valid_dataset, 1)\n",
        "    valid_output_lstm_last = inference_model(model, valid_dataset)\n",
        "    test_output_lstm_last = inference_model(model, test_dataset)\n",
        "    # roc_auc_score(valid_labels, valid_output_lstm_last)\n",
        "    dict_outputDF[f'lstm_pred_{i}'] = valid_output_lstm_last + test_output_lstm_last\n",
        "    valid_sum+=valid_output_lstm_last\n",
        "roc_auc_score(valid_labels, valid_sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "4o8za0oMMh67",
        "outputId": "54ac3916-36c6-4511-f539-d732c0499c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 1836/9271 [00:08<00:34, 216.70it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-238cf448bca5>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mvalid_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_output_lstm_last\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvalid_output_lstm_last\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_roc_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mvalid_output_lstm_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtest_output_lstm_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-e6816531a122>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_dataset, valid_dataset, num_epochs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mloss_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_change_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_token_change\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mloss_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_label\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         return F.binary_cross_entropy_with_logits(input, target,\n\u001b[0m\u001b[1;32m    726\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Target size ({target.size()}) must be the same as input size ({input.size()})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Znz7uAzpQwq9",
        "outputId": "14cef9f2-f5e3-4b11-cf8a-5550bf145cc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.4353304, 1.4518121, 9.049635 , ..., 2.4956572, 6.604525 ,\n",
              "       1.2105738], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(dict_outputDF)\n",
        "df.to_csv('/content/drive/MyDrive/lstm_esemble.csv', index=False)"
      ],
      "metadata": {
        "id": "YHP70Zi0Mspd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "# Setting the device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Transform class\n",
        "class Transform(nn.Module):\n",
        "    def __init__(self, outfea, d):\n",
        "        super(Transform, self).__init__()\n",
        "        self.qff = nn.Linear(outfea, outfea)\n",
        "        self.kff = nn.Linear(outfea, outfea)\n",
        "        self.vff = nn.Linear(outfea, outfea)\n",
        "\n",
        "        self.ln = nn.LayerNorm(outfea)\n",
        "        self.lnff = nn.LayerNorm(outfea)\n",
        "\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(outfea, outfea),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(outfea, outfea)\n",
        "        )\n",
        "\n",
        "        self.d = d\n",
        "\n",
        "    def forward(self, x):\n",
        "        query = self.qff(x)\n",
        "        key = self.kff(x)\n",
        "        value = self.vff(x)\n",
        "\n",
        "        query = torch.cat(torch.split(query, self.d, -1), 0).permute(0,2,1,3)\n",
        "        key = torch.cat(torch.split(key, self.d, -1), 0).permute(0,2,3,1)\n",
        "        value = torch.cat(torch.split(value, self.d, -1), 0).permute(0,2,1,3)\n",
        "\n",
        "        A = torch.matmul(query, key)\n",
        "        A /= (self.d ** 0.5)\n",
        "        A = torch.softmax(A, -1)\n",
        "\n",
        "        value = torch.matmul(A ,value)\n",
        "        value = torch.cat(torch.split(value, x.shape[0], 0), -1).permute(0,2,1,3)\n",
        "        value += x\n",
        "\n",
        "        value = self.ln(value)\n",
        "        x = self.ff(value) + value\n",
        "        return self.lnff(x)\n",
        "\n",
        "# PositionalEncoding class\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, outfea):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.outfea = outfea if outfea % 2 == 0 else outfea + 1\n",
        "\n",
        "    def forward(self, x):\n",
        "        max_len = x.size(1)\n",
        "        pe = torch.zeros(max_len, self.outfea).to(x.device)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, self.outfea, 2).float() * -(math.log(10000.0) / self.outfea))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).unsqueeze(2)  # [1, T, 1, F]\n",
        "        x = x + pe[:,:,:,:x.size(-1)]  # Adjust positional encoding size to match input size\n",
        "        return x\n",
        "\n",
        "# SGNN class\n",
        "class SGNN(nn.Module):\n",
        "    def __init__(self, outfea):\n",
        "        super(SGNN, self).__init__()\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(outfea, outfea),\n",
        "            nn.Linear(outfea, outfea)\n",
        "        )\n",
        "        self.ff1 = nn.Linear(outfea, outfea)\n",
        "\n",
        "    def forward(self, x):\n",
        "        p = self.ff(x)\n",
        "        a = torch.matmul(p, p.transpose(-1,-2))\n",
        "        R = torch.relu(torch.softmax(a, -1)) + torch.eye(x.shape[1]).to(device)\n",
        "\n",
        "        D = (R.sum(-1) ** -0.5)\n",
        "        D[torch.isinf(D)] = 0.\n",
        "        D = torch.diag_embed(D)\n",
        "\n",
        "        A = torch.matmul(torch.matmul(D, R), D)\n",
        "        x = torch.relu(self.ff1(torch.matmul(A, x)))\n",
        "        return x\n",
        "\n",
        "# GRU class\n",
        "class GRU(nn.Module):\n",
        "    def __init__(self, outfea):\n",
        "        super(GRU, self).__init__()\n",
        "        self.ff = nn.Linear(2*outfea, 2*outfea)\n",
        "        self.zff = nn.Linear(2*outfea, outfea)\n",
        "        self.outfea = outfea\n",
        "\n",
        "    def forward(self, x, xh):\n",
        "        r, u = torch.split(torch.sigmoid(self.ff(torch.cat([x, xh], -1))), self.outfea, -1)\n",
        "        z = torch.tanh(self.zff(torch.cat([x, r*xh], -1)))\n",
        "        x = u * z + (1-u) * xh\n",
        "        return x\n",
        "\n",
        "\n",
        "class STGNNwithGRU(nn.Module):\n",
        "    def __init__(self, outfea):\n",
        "        super(STGNNwithGRU, self).__init__()\n",
        "        self.sgnn = SGNN(outfea)  # 使用单个SGNN实例\n",
        "        self.gru = GRU(outfea)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, N, F = x.shape\n",
        "        hidden_state = torch.zeros([B, N, F]).to(device)\n",
        "        output = []\n",
        "\n",
        "        for i in range(T):\n",
        "            gx = self.sgnn(x[:, i, :, :])  # 在每个时间步使用相同的SGNN实例\n",
        "            gh = hidden_state\n",
        "            if i != 0:\n",
        "                gh = self.sgnn(hidden_state)  # 重复使用SGNN实例\n",
        "            hidden_state = self.gru(gx, gh)\n",
        "            output.append(hidden_state)\n",
        "\n",
        "        output = torch.stack(output, 1)\n",
        "        return output\n",
        "\n",
        "\n",
        "# Continuing with the STGNNwithGRU class\n",
        "class STGNNwithGRU(nn.Module):\n",
        "    def __init__(self, outfea):\n",
        "        super(STGNNwithGRU, self).__init__()\n",
        "        self.sgnn = SGNN(outfea)  # Using a single SGNN instance\n",
        "        self.gru = GRU(outfea)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, N, F = x.shape\n",
        "        hidden_state = torch.zeros([B, N, F]).to(device)\n",
        "        output = []\n",
        "\n",
        "        for i in range(T):\n",
        "            gx = self.sgnn(x[:, i, :, :])  # Use the same SGNN instance at each time step\n",
        "            gh = hidden_state\n",
        "            if i != 0:\n",
        "                gh = self.sgnn(hidden_state)  # Reuse the SGNN instance\n",
        "            hidden_state = self.gru(gx, gh)\n",
        "            output.append(hidden_state)\n",
        "\n",
        "        output = torch.stack(output, 1)\n",
        "        return output\n",
        "\n",
        "# STGNN class\n",
        "class STGNN(nn.Module):\n",
        "    def __init__(self, infea, outfea, L, d):\n",
        "        super(STGNN, self).__init__()\n",
        "        self.start_emb = nn.Linear(infea, outfea)\n",
        "        self.adjust_emb = nn.Linear(outfea, infea)  # Additional layer for dimension adjustment\n",
        "        self.end_emb = nn.Linear(infea, infea)\n",
        "\n",
        "        self.stgnnwithgru = nn.ModuleList([STGNNwithGRU(outfea) for i in range(L)])\n",
        "        self.positional_encoding = PositionalEncoding(outfea)\n",
        "        self.transform = nn.ModuleList([Transform(outfea, d) for i in range(L)])\n",
        "\n",
        "        self.fc_token_change = nn.Linear(infea, infea)  # Predicts next time step change\n",
        "        self.fc_label = nn.Linear(infea, 1)  # Predicts label\n",
        "\n",
        "        self.L = L\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, F = x.shape\n",
        "        x = x.unsqueeze(2)  # Add spatial dimension [B, T, 1, F]\n",
        "        x = self.start_emb(x)\n",
        "        for i in range(self.L):\n",
        "            x = self.stgnnwithgru[i](x)\n",
        "        x = self.positional_encoding(x)\n",
        "        for i in range(self.L):\n",
        "            x = self.transform[i](x)\n",
        "        x = self.adjust_emb(x)  # Adjust dimensions\n",
        "        x = self.end_emb(x)\n",
        "        x = x.squeeze(2)  # Remove spatial dimension [B, T, F]\n",
        "\n",
        "        token_change = self.fc_token_change(x)\n",
        "        labels = self.fc_label(x).squeeze(-1)\n",
        "\n",
        "        return token_change, labels\n",
        "\n",
        "# Instantiate and test the model\n",
        "model = STGNN(infea=171, outfea=64, L=3, d=8).to(device)\n",
        "test_input = torch.rand(1, 13, 171).to(device)\n",
        "token_change, labels = model(test_input)\n",
        "\n",
        "# Check the shapes of the outputs\n",
        "token_change.shape, labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckvobRgzxHwc",
        "outputId": "d9d673a5-eef7-4b33-a515-fc679804b2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 13, 171]), torch.Size([1, 13]))"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "best_model = train_model(model, train_dataset, valid_dataset, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "BMILGjfK-ehQ",
        "outputId": "2b0b0843-c5d4-4c53-90f6-89e7855dca87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-6c252d3cc195>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-101-e42e5e7dd4cc>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataset, valid_dataset, num_epochs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtoken_change_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mactual_token_change\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-114-64e8eaddd855>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstgnnwithgru\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-114-64e8eaddd855>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reuse the SGNN instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-114-64e8eaddd855>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1680\u001b[0m     \u001b[0;31m# See full discussion on the problems with returning `Union` here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0;31m# https://github.com/microsoft/pyright/issues/4213\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save all"
      ],
      "metadata": {
        "id": "yK3ZciRTIn2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZB8hdVKKFeZ",
        "outputId": "a5467af5-a0c3-4633-ceac-ea4aedcbb79b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_ids = df_valid['id'].tolist()\n",
        "test_ids = df_test['id'].tolist()\n",
        "combined_ids = valid_ids + test_ids\n",
        "# Removing adjacent duplicates\n",
        "unique_ids = [combined_ids[i] for i in range(len(combined_ids)) if i == 0 or combined_ids[i] != combined_ids[i-1]]"
      ],
      "metadata": {
        "id": "eG9Y6jmRMIRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_ids = df_valid['id'].tolist()\n",
        "test_ids = df_test['id'].tolist()\n",
        "combined_ids = valid_ids + test_ids\n",
        "# Removing adjacent duplicates\n",
        "unique_ids = [combined_ids[i] for i in range(len(combined_ids)) if i == 0 or combined_ids[i] != combined_ids[i-1]]\n",
        "dict_outputDF = {\n",
        "    \"id\": unique_ids,\n",
        "    \"subset\": [\"valid\"] * len(valid_labels)+[\"test\"]*len(test_labels),\n",
        "    \"label\": valid_labels.tolist()+test_labels.tolist(),\n",
        "    \"gnn_pred\": score_valid_gnn.tolist()+score_test_gnn.tolist(),\n",
        "    \"lstm_pred_1\": valid_output_lstm_last+test_output_lstm_last,\n",
        "    \"lstm_pred_2\": valid_output_lstm_best+test_output_lstm_best,\n",
        "}\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(dict_outputDF)\n",
        "df.to_csv('/content/drive/MyDrive/cogito/gnn_lstm.csv', index=False)"
      ],
      "metadata": {
        "id": "nT9N3P02IpX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dict_outputDF['id'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B2Qhm8hL3HH",
        "outputId": "2af8d703-021c-4486-8766-e23498842cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5261"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dict_outputDF['gnn_pred'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIVHL3_8L4qz",
        "outputId": "67d4d9c6-94c7-40e3-ad35-ef20d473230b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5261"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(dict_outputDF)\n",
        "df.to_csv('/gdrive/MyDrive/gnn_lstm.csv', index=False)"
      ],
      "metadata": {
        "id": "X0AXeMT8JGbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SAbuTbSJL1DP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}